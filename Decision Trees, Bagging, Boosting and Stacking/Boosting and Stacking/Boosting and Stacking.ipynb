{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting and Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Human Activity Recognition with Smartphones database, which was built from the recordings of study participants performing activities of daily living (ADL) while carrying a smartphone with an embedded inertial sensors. The objective is to classify activities into one of the six activities (walking, walking upstairs, walking downstairs, sitting, standing, and laying) performed.\n",
    "\n",
    "For each record in the dataset it is provided:\n",
    "\n",
    "- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.\n",
    "- Triaxial angular velocity from the gyroscope.\n",
    "- A 561-feature vector with time and frequency domain variables.\n",
    "- Its activity label.\n",
    "\n",
    "More information about the features, and the data source is available on the website below:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Human_Activity_Recognition_Using_Smartphones_Data.csv'\n",
    "ds = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299, 562)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that the data has quite a few predictor columns.\n",
    "\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    561\n",
       "object       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The only non-float is the categories column, which is the predicted column.\n",
    "\n",
    "ds.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    562\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking care of missing data\n",
    "# We observe that there are no missing values\n",
    "\n",
    "ds.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.274347</td>\n",
       "      <td>-0.017743</td>\n",
       "      <td>-0.108925</td>\n",
       "      <td>-0.607784</td>\n",
       "      <td>-0.510191</td>\n",
       "      <td>-0.613064</td>\n",
       "      <td>-0.633593</td>\n",
       "      <td>-0.525697</td>\n",
       "      <td>-0.614989</td>\n",
       "      <td>-0.466732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126708</td>\n",
       "      <td>-0.298592</td>\n",
       "      <td>-0.617700</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.009219</td>\n",
       "      <td>-0.496522</td>\n",
       "      <td>0.063255</td>\n",
       "      <td>-0.054284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.067628</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.053033</td>\n",
       "      <td>0.438694</td>\n",
       "      <td>0.500240</td>\n",
       "      <td>0.403657</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.484201</td>\n",
       "      <td>0.399034</td>\n",
       "      <td>0.538707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245443</td>\n",
       "      <td>0.320199</td>\n",
       "      <td>0.308796</td>\n",
       "      <td>0.336591</td>\n",
       "      <td>0.447364</td>\n",
       "      <td>0.616188</td>\n",
       "      <td>0.484770</td>\n",
       "      <td>0.511158</td>\n",
       "      <td>0.305468</td>\n",
       "      <td>0.268898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.262625</td>\n",
       "      <td>-0.024902</td>\n",
       "      <td>-0.121019</td>\n",
       "      <td>-0.992360</td>\n",
       "      <td>-0.976990</td>\n",
       "      <td>-0.979137</td>\n",
       "      <td>-0.993293</td>\n",
       "      <td>-0.977017</td>\n",
       "      <td>-0.979064</td>\n",
       "      <td>-0.935788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019481</td>\n",
       "      <td>-0.536174</td>\n",
       "      <td>-0.841847</td>\n",
       "      <td>-0.124694</td>\n",
       "      <td>-0.287031</td>\n",
       "      <td>-0.493108</td>\n",
       "      <td>-0.389041</td>\n",
       "      <td>-0.817288</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>-0.131880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.277174</td>\n",
       "      <td>-0.017162</td>\n",
       "      <td>-0.108596</td>\n",
       "      <td>-0.943030</td>\n",
       "      <td>-0.835032</td>\n",
       "      <td>-0.850773</td>\n",
       "      <td>-0.948244</td>\n",
       "      <td>-0.843670</td>\n",
       "      <td>-0.845068</td>\n",
       "      <td>-0.874825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136245</td>\n",
       "      <td>-0.335160</td>\n",
       "      <td>-0.703402</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>0.017192</td>\n",
       "      <td>-0.007186</td>\n",
       "      <td>-0.715631</td>\n",
       "      <td>0.182028</td>\n",
       "      <td>-0.003882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.288354</td>\n",
       "      <td>-0.010625</td>\n",
       "      <td>-0.097589</td>\n",
       "      <td>-0.250293</td>\n",
       "      <td>-0.057336</td>\n",
       "      <td>-0.278737</td>\n",
       "      <td>-0.302033</td>\n",
       "      <td>-0.087405</td>\n",
       "      <td>-0.288149</td>\n",
       "      <td>-0.014641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288960</td>\n",
       "      <td>-0.113167</td>\n",
       "      <td>-0.487981</td>\n",
       "      <td>0.149005</td>\n",
       "      <td>0.291490</td>\n",
       "      <td>0.536137</td>\n",
       "      <td>0.365996</td>\n",
       "      <td>-0.521503</td>\n",
       "      <td>0.250790</td>\n",
       "      <td>0.102970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "count       10299.000000       10299.000000       10299.000000   \n",
       "mean            0.274347          -0.017743          -0.108925   \n",
       "std             0.067628           0.037128           0.053033   \n",
       "min            -1.000000          -1.000000          -1.000000   \n",
       "25%             0.262625          -0.024902          -0.121019   \n",
       "50%             0.277174          -0.017162          -0.108596   \n",
       "75%             0.288354          -0.010625          -0.097589   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "count      10299.000000      10299.000000      10299.000000      10299.000000   \n",
       "mean          -0.607784         -0.510191         -0.613064         -0.633593   \n",
       "std            0.438694          0.500240          0.403657          0.413333   \n",
       "min           -1.000000         -1.000000         -1.000000         -1.000000   \n",
       "25%           -0.992360         -0.976990         -0.979137         -0.993293   \n",
       "50%           -0.943030         -0.835032         -0.850773         -0.948244   \n",
       "75%           -0.250293         -0.057336         -0.278737         -0.302033   \n",
       "max            1.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  \\\n",
       "count      10299.000000      10299.000000      10299.000000  ...   \n",
       "mean          -0.525697         -0.614989         -0.466732  ...   \n",
       "std            0.484201          0.399034          0.538707  ...   \n",
       "min           -1.000000         -1.000000         -1.000000  ...   \n",
       "25%           -0.977017         -0.979064         -0.935788  ...   \n",
       "50%           -0.843670         -0.845068         -0.874825  ...   \n",
       "75%           -0.087405         -0.288149         -0.014641  ...   \n",
       "max            1.000000          1.000000          1.000000  ...   \n",
       "\n",
       "       fBodyBodyGyroJerkMag-meanFreq()  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "count                     10299.000000                     10299.000000   \n",
       "mean                          0.126708                        -0.298592   \n",
       "std                           0.245443                         0.320199   \n",
       "min                          -1.000000                        -1.000000   \n",
       "25%                          -0.019481                        -0.536174   \n",
       "50%                           0.136245                        -0.335160   \n",
       "75%                           0.288960                        -0.113167   \n",
       "max                           1.000000                         1.000000   \n",
       "\n",
       "       fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "count                     10299.000000                 10299.000000   \n",
       "mean                         -0.617700                     0.007705   \n",
       "std                           0.308796                     0.336591   \n",
       "min                          -1.000000                    -1.000000   \n",
       "25%                          -0.841847                    -0.124694   \n",
       "50%                          -0.703402                     0.008146   \n",
       "75%                          -0.487981                     0.149005   \n",
       "max                           1.000000                     1.000000   \n",
       "\n",
       "       angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "count                          10299.000000                      10299.000000   \n",
       "mean                               0.002648                          0.017683   \n",
       "std                                0.447364                          0.616188   \n",
       "min                               -1.000000                         -1.000000   \n",
       "25%                               -0.287031                         -0.493108   \n",
       "50%                                0.007668                          0.017192   \n",
       "75%                                0.291490                          0.536137   \n",
       "max                                1.000000                          1.000000   \n",
       "\n",
       "       angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "count                          10299.000000          10299.000000   \n",
       "mean                              -0.009219             -0.496522   \n",
       "std                                0.484770              0.511158   \n",
       "min                               -1.000000             -1.000000   \n",
       "25%                               -0.389041             -0.817288   \n",
       "50%                               -0.007186             -0.715631   \n",
       "75%                                0.365996             -0.521503   \n",
       "max                                1.000000              1.000000   \n",
       "\n",
       "       angle(Y,gravityMean)  angle(Z,gravityMean)  \n",
       "count          10299.000000          10299.000000  \n",
       "mean               0.063255             -0.054284  \n",
       "std                0.305468              0.268898  \n",
       "min               -1.000000             -1.000000  \n",
       "25%                0.002151             -0.131880  \n",
       "50%                0.182028             -0.003882  \n",
       "75%                0.250790              0.102970  \n",
       "max                1.000000              1.000000  \n",
       "\n",
       "[8 rows x 561 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the below (and above), we observe that the minimum and maximum value for the float columns is -1.0 and 1.0, respectively. However, scaling is never required for tree-based methods. As this notebook also regards Stacking, for Stacking methods it is beneficial to use scaling as we are not limited to using tree-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "float_columns = (ds.dtypes == np.float)\n",
    "\n",
    "# Verify that the maximum of all float columns is 1.0\n",
    "print((ds.loc[:,float_columns].max()== 1.0).all())\n",
    "\n",
    "# Verify that the minimum of all float columns is -1.0\n",
    "print((ds.loc[:,float_columns].min()== -1.0).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS',\n",
       "       'WALKING_UPSTAIRS'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "ds['Activity'] = le.fit_transform(ds['Activity'])\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 3, 4, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.Activity.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Dataset into the Training Set and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the dataset into the training set and test set. A stratified split was not used here. If there are issues with any of the error metrics on the test set, it can be a good idea to start model fitting over using a stratified split. Boosting is a pretty powerful model, so it may not be necessary in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.188756\n",
       "2    0.185067\n",
       "1    0.172541\n",
       "3    0.167201\n",
       "5    0.149917\n",
       "4    0.136518\n",
       "Name: Activity, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.Activity.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_columns = [x for x in ds.columns if x != 'Activity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds[feature_columns], ds['Activity'],\n",
    "                                                    test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7209, 561), (7209,), (3090, 561), (3090,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Models to the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now:\n",
    "\n",
    "- Fit gradient boosted tree models with all parameters set to their defaults following tree numbers `(n_estimators = [15, 25, 50, 100, 200, 400])` and evaluate the accuracy on the test data for each of these models.\n",
    "- Plot the accuracy as a function of estimator number.\n",
    "\n",
    "Note: There is no out-of-bag error for boosted models. And the `warm_flag = True` setting has a bug in the gradient boosted model, so we will not use it. We'll simply create the model inside the `for loop` and set the number of estimators at a time. This will make the fitting take a little longer. Additionally, boosting models tend to take longer to fit than bagged ones because the decision stumps must be fit successively.\n",
    "\n",
    "**Note: The below code took a long time to run, I left it running overnight.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model with 15 trees\n",
      "Fitting model with 25 trees\n",
      "Fitting model with 50 trees\n",
      "Fitting model with 100 trees\n",
      "Fitting model with 200 trees\n",
      "Fitting model with 400 trees\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trees</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15.0</td>\n",
       "      <td>0.051133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25.0</td>\n",
       "      <td>0.033981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50.0</td>\n",
       "      <td>0.019417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100.0</td>\n",
       "      <td>0.013592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200.0</td>\n",
       "      <td>0.011003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400.0</td>\n",
       "      <td>0.010356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            error\n",
       "n_trees          \n",
       "15.0     0.051133\n",
       "25.0     0.033981\n",
       "50.0     0.019417\n",
       "100.0    0.013592\n",
       "200.0    0.011003\n",
       "400.0    0.010356"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "error_list = list()\n",
    "\n",
    "# Iterate through various possibilities for number of trees\n",
    "tree_list = [15, 25, 50, 100, 200, 400]\n",
    "for n_trees in tree_list:\n",
    "    \n",
    "    # Initialize the gradient boost classifier\n",
    "    GBC = GradientBoostingClassifier(n_estimators=n_trees, random_state=42)\n",
    "\n",
    "    # Fit the model\n",
    "    print(f'Fitting model with {n_trees} trees')\n",
    "    GBC.fit(X_train.values, y_train.values)\n",
    "    y_pred = GBC.predict(X_test)\n",
    "\n",
    "    # Get the error\n",
    "    error = 1.0 - accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store it\n",
    "    error_list.append(pd.Series({'n_trees': n_trees, 'error': error}))\n",
    "\n",
    "error_df = pd.concat(error_list, axis=1).T.set_index('n_trees')\n",
    "\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increased the number of trees, we see the error diminishing. This is observed graphically below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trees</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15.0</td>\n",
       "      <td>0.051133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25.0</td>\n",
       "      <td>0.033981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50.0</td>\n",
       "      <td>0.019417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100.0</td>\n",
       "      <td>0.013592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200.0</td>\n",
       "      <td>0.011003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400.0</td>\n",
       "      <td>0.010356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            error\n",
       "n_trees          \n",
       "15.0     0.051133\n",
       "25.0     0.033981\n",
       "50.0     0.019417\n",
       "100.0    0.013592\n",
       "200.0    0.011003\n",
       "400.0    0.010356"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "# Create the plot\n",
    "ax = error_df.plot(marker='o', figsize=(12, 8), linewidth=5)\n",
    "\n",
    "# Set parameters\n",
    "ax.set(xlabel='Number of Trees', ylabel='Error')\n",
    "ax.set_xlim(0, max(error_df.index)*1.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now:\n",
    "\n",
    "- Use a grid search with cross-validation and fit a new gradient boosted classifier with the same list of estimators as the steps above. Also, we will try varying the learning rates (0.1, 0.01, 0.001, etc.), the subsampling value (1.0 or 0.5), and the number of maximum features (1, 2, ... etc).\n",
    "- Examine the parameters of the best fit model.\n",
    "- Calculate relevant error metrics on this model and examine the confusion matrix.\n",
    "\n",
    "**Note:** The lower the learning rate, the higher the number of trees we wish to have or vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# The parameters to be fit\n",
    "param_grid = {'n_estimators': tree_list,\n",
    "              'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
    "              'subsample': [1.0, 0.5],\n",
    "              'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "# The grid search object\n",
    "GV_GBC = GridSearchCV(GradientBoostingClassifier(random_state=42), \n",
    "                      param_grid=param_grid, \n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1)\n",
    "\n",
    "# Do the grid search\n",
    "GV_GBC = GV_GBC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below step, we are performing pickling. Here, we serialise our Python objects and save them as bytes, so they are saved in a file. If we wish to introduce them as Python objects again, we can pull them out using the pickle functionality. This works by doing `pickle.dump` and thats just dumping our Python objects into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(GV_GBC, open('gv_gbc.p', 'wb')) # w - write, b - bytes\n",
    "\n",
    "GV_GBC = pickle.load(open('gv_gbc.p', 'rb')) # r - read, b - bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_features=4, n_estimators=400, random_state=42)\n",
      "{'learning_rate': 0.1, 'max_features': 4, 'n_estimators': 400, 'subsample': 1.0}\n",
      "0.9866833307506248\n"
     ]
    }
   ],
   "source": [
    "print(GV_GBC.best_estimator_)\n",
    "print(GV_GBC.best_params_)\n",
    "print(GV_GBC.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(GV_GBC.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       597\n",
      "           1       0.97      0.97      0.97       561\n",
      "           2       0.97      0.97      0.97       547\n",
      "           3       1.00      1.00      1.00       540\n",
      "           4       1.00      1.00      1.00       419\n",
      "           5       1.00      0.99      0.99       426\n",
      "\n",
      "    accuracy                           0.99      3090\n",
      "   macro avg       0.99      0.99      0.99      3090\n",
      "weighted avg       0.99      0.99      0.99      3090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = GV_GBC.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[597   0   0   0   0   0]\n",
      " [  0 544  17   0   0   2]\n",
      " [  0  17 530   0   0   0]\n",
      " [  0   0   0 538   0   1]\n",
      " [  0   0   0   1 418   1]\n",
      " [  0   0   0   1   1 422]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what we have done above, we will now:\n",
    "\n",
    "- Create an AdaBoost model and fit it using grid search with a range of estimators between 100 and 200.\n",
    "- Compare the errors from AdaBoost to those from the GradientBoostedClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1))\n",
    "\n",
    "param_grid = {'n_estimators': [100, 150, 200],\n",
    "              'learning_rate': [0.01, 0.001]}\n",
    "\n",
    "GV_ABC = GridSearchCV(ABC,\n",
    "                      param_grid=param_grid, \n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1)\n",
    "\n",
    "GV_ABC = GV_ABC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   learning_rate=0.01, n_estimators=100)\n",
      "{'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.712172160456456\n"
     ]
    }
   ],
   "source": [
    "print(GV_ABC.best_estimator_)\n",
    "print(GV_ABC.best_params_)\n",
    "print(GV_ABC.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The issues with class 1 and 2 appear to have become more problematic. Also note other issues for classes 3 - 5. AdaBoost is very sensitive to outliers, so that could be the problem here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       600\n",
      "           1       0.00      1.00      0.00         1\n",
      "           2       1.00      0.49      0.66      1106\n",
      "           3       0.92      0.84      0.88       589\n",
      "           4       0.73      0.95      0.82       320\n",
      "           5       0.89      0.80      0.84       474\n",
      "\n",
      "    accuracy                           0.75      3090\n",
      "   macro avg       0.76      0.85      0.70      3090\n",
      "weighted avg       0.94      0.75      0.81      3090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = GV_ABC.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[597   0   0   0   0   0]\n",
      " [  1   1 561   0   0   0]\n",
      " [  2   0 545   0   0   0]\n",
      " [  0   0   0 497   6  36]\n",
      " [  0   0   0  55 305  60]\n",
      " [  0   0   0  37   9 378]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following steps, we will now:\n",
    "    \n",
    "- Fit a logistic regression model with regularization.\n",
    "- Using `VotingClassifier`, fit the logistic regression model along with either the GradientBoostedClassifier or the AdaBoost model (or both) from the above steps.\n",
    "- Determine the error as before and compare the results to the appropriate gradient boosted model(s).\n",
    "- Plot the confusion matrix for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# L2 regularised logistic regression\n",
    "LR_L2 = LogisticRegression(penalty='l2', max_iter=500, solver='saga').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       598\n",
      "           1       0.95      0.96      0.95       558\n",
      "           2       0.95      0.95      0.95       547\n",
      "           3       1.00      0.99      0.99       544\n",
      "           4       0.98      1.00      0.99       413\n",
      "           5       1.00      0.98      0.99       430\n",
      "\n",
      "    accuracy                           0.98      3090\n",
      "   macro avg       0.98      0.98      0.98      3090\n",
      "weighted avg       0.98      0.98      0.98      3090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = LR_L2.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[597   0   0   0   0   0]\n",
      " [  1 533  25   0   0   4]\n",
      " [  0  25 522   0   0   0]\n",
      " [  0   0   0 538   0   1]\n",
      " [  0   0   0   4 413   3]\n",
      " [  0   0   0   2   0 422]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And now the Stacked model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# The combined model--logistic regression and gradient boosted trees\n",
    "estimators = [('LR_L2', LR_L2), ('GBC', GV_GBC)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Although we have not performed this step here, it is often desirable to train this model using an additional hold-out data set and/or with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "VC = VotingClassifier(estimators, voting='soft')\n",
    "VC = VC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The performance for the voting classifier should improve relative to either logistic regression or gradient boosted trees alone. However, the fact that logistic regression does almost as well as gradient boosted trees is an important reminder to try the simplest model first. In some cases, its performance will be good enough. This should be kept in mind in all business settings as time is crucial, and the tradeoff between model accuracy and time spent working on the model should be optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       597\n",
      "           1       0.97      0.96      0.97       563\n",
      "           2       0.97      0.97      0.97       547\n",
      "           3       1.00      1.00      1.00       539\n",
      "           4       1.00      1.00      1.00       420\n",
      "           5       0.99      1.00      0.99       424\n",
      "\n",
      "    accuracy                           0.99      3090\n",
      "   macro avg       0.99      0.99      0.99      3090\n",
      "weighted avg       0.99      0.99      0.99      3090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = VC.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[597   0   0   0   0   0]\n",
      " [  0 540  19   0   0   4]\n",
      " [  0  16 531   0   0   0]\n",
      " [  0   0   0 538   0   1]\n",
      " [  0   0   0   1 419   0]\n",
      " [  0   0   0   1   0 423]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
